{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pruthvi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\pruthvi\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools    \n",
    "import cv2\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import numpy.random as rng\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from sklearn.utils import shuffle\n",
    "import nibabel as nib #reading MR images\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Save as Pickle file\n",
    "\n",
    "DATA_PATH = 'E:\\\\005Balgrist\\\\009Longitudinal_prediction\\\\Data\\\\Patients' #% where the data is organized\n",
    "\n",
    "\n",
    "lst = os.listdir(DATA_PATH)\n",
    "\n",
    "if '.DS_Store' in lst:\n",
    "    lst.remove('.DS_Store')\n",
    "\n",
    "n=len(lst)\n",
    "Time_points_list=[\"month_06\",\"month_12\",\"month_24\"]\n",
    "n_time=len(Time_points_list)\n",
    "\n",
    "\n",
    "Subjects_list=list(itertools.chain.from_iterable((itertools.repeat(i, n_time) for i in lst)))\n",
    "\n",
    "Time_points_list=list(itertools.chain.from_iterable(itertools.repeat(Time_points_list, n)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_df = pd.DataFrame({\"subject\": Subjects_list, \"Time_point \": Time_points_list})\n",
    "original_df.to_pickle(\"/Users/pruthvi_local/Desktop/Lesion_Segmentation/01_preprocess/subject_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3a3716e83056>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"E:\\005Balgrist\\006VBM_July_2018\\01_Data_NIFTI\\MPRAGE\\Controls\\*.nii\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mff\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "ff = glob.glob(r\"E:\\005Balgrist\\006VBM_July_2018\\01_Data_NIFTI\\MPRAGE\\Controls\\*.nii\")\n",
    "\n",
    "ff[0]\n",
    "len(ff)\n",
    "images = []\n",
    "for f in range(len(ff)):\n",
    "    a = nib.load(ff[f])\n",
    "    a = a.get_data()\n",
    "    a = a[:,78:129,:]\n",
    "    for i in range(a.shape[1]):\n",
    "        images.append((a[:,i,:]))\n",
    "print (a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,0,:].shape\n",
    "images = np.asarray(images)\n",
    "images.shape\n",
    "images = images.reshape(-1, 256,320,1)\n",
    "images.shape\n",
    "m = np.max(images)\n",
    "mi = np.min(images)\n",
    "\n",
    "m, mi\n",
    "images = (images - mi) / (m - mi)\n",
    "\n",
    "np.min(images), np.max(images)\n",
    "#temp = np.zeros([306,259,323,1])\n",
    "#temp[:,3:,3:,:] = images\n",
    "\n",
    "#images=temp\n",
    "\n",
    "train_X,valid_X,train_ground,valid_ground = train_test_split(images,images,test_size=0.2,random_state=13)\n",
    "\n",
    "# Shapes of training set\n",
    "print(\"Dataset (images) shape: {shape}\".format(shape=images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(train_X[0], (256,320))\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(valid_X[0], (256,320))\n",
    "plt.imshow(curr_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "epochs = 50\n",
    "inChannel = 1\n",
    "x, y = 256, 320\n",
    "input_img = Input(shape = (x, y, inChannel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(input_img):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "\n",
    "    #decoder\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 128\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    up1 = UpSampling2D((2,2))(conv4) # 14 x 14 x 128\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 64\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    up2 = UpSampling2D((2,2))(conv5) # 28 x 28 x 64\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, autoencoder(input_img))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = autoencoder_train.history['loss']\n",
    "val_loss = autoencoder_train.history['val_loss']\n",
    "epochs = range(50)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = autoencoder.save_weights('autoencoder_mri.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
